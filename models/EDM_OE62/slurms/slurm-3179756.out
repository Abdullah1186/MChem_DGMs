/var/spool/slurmd/job3179756/slurm_script: line 11: module: command not found
/var/spool/slurmd/job3179756/slurm_script: line 12: module: command not found
/var/spool/slurmd/job3179756/slurm_script: line 13: module: command not found
/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  result = getattr(asarray(obj), method)(*args, **kwds)
wandb: Currently logged in as: abdullahalfekaiki (abdullahalfekaiki-university-of-warwick) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /users/afekaiki/EDM/wandb/run-20250222_134429-ucdxoq97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run edm_oe62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/abdullahalfekaiki-university-of-warwick/EDM_oe62
wandb: üöÄ View run at https://wandb.ai/abdullahalfekaiki-university-of-warwick/EDM_oe62/runs/ucdxoq97
Namespace(aggregation_method='sum', attention=True, augment_noise=0, batch_size=64, break_train_epoch=False, clip_grad=True, condition_time=True, conditioning=[], cuda=True, data_augmentation=False, dataset='oe62', dequantization='argmax_variational', diffusion_loss_type='l2', diffusion_noise_precision=1e-05, diffusion_noise_schedule='polynomial_2', diffusion_steps=1000, dp=True, ema_decay=0.9999, exp_name='edm_oe62', filter_molecule_size=None, filter_n_atoms=None, generate_epochs=1, include_charges=False, inv_sublayers=1, lr=0.0001, model='egnn_dynamics', n_epochs=3000, n_layers=4, n_report_steps=50, n_stability_samples=500, nf=256, no_cuda=False, no_wandb=False, norm_constant=1, normalization_factor=1.0, normalize_factors=[1, 4, 10], num_workers=0, ode_regularization=0.001, online=True, probabilistic_model='diffusion', remove_h=False, resume=None, save_model=True, sequential=False, sin_embedding=False, start_epoch=0, tanh=True, test_epochs=1, trace='hutch', visualize_every_batch=10000, wandb_usr=None)
Entropy of n_nodes: H[N] -4.140960693359375
alphas2 [9.99990000e-01 9.99988000e-01 9.99982000e-01 ... 2.59676966e-05
 1.39959211e-05 1.00039959e-05]
gamma [-11.51291546 -11.33059532 -10.92513058 ...  10.55863126  11.17673063
  11.51251595]
Epoch: 0, iter: 0/769, Loss 5.37, NLL: 5.37, RegTerm: 0.0, GradNorm: 4345.7
Clipped gradient with value 106563504.0 while allowed 7207.1
Clipped gradient with value 99009.1 while allowed 10562.2
Clipped gradient with value 17008.5 while allowed 11599.2
Clipped gradient with value 62023924.0 while allowed 13909.8
Clipped gradient with value 2239228.0 while allowed 14094.4
Clipped gradient with value 541618.1 while allowed 10068.8
Clipped gradient with value 481327.1 while allowed 10635.3
Epoch: 0, iter: 50/769, Loss 4.32, NLL: 4.32, RegTerm: 0.0, GradNorm: 309.6
Clipped gradient with value 81526.8 while allowed 10766.8
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33medm_oe62[0m at: [34mhttps://wandb.ai/abdullahalfekaiki-university-of-warwick/EDM_oe62/runs/ucdxoq97[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250222_134429-ucdxoq97/logs[0m
Traceback (most recent call last):
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/main_oe62.py", line 280, in <module>
    main()
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/main_oe62.py", line 236, in main
    train_test.train_epoch(args, dataloaders['train'], epoch, model, model_dp, model_ema, ema, device, dtype,
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/train_test.py", line 53, in train_epoch
    nll, reg_term, mean_abs_z = losses.compute_loss_and_nll(args, model_dp, nodes_dist,
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/qm9/losses.py", line 23, in compute_loss_and_nll
    nll = generative_model(x, h, node_mask, edge_mask, context)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py", line 701, in forward
    loss, loss_dict = self.compute_loss(x, h, node_mask, edge_mask, context, t0_always=False)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py", line 609, in compute_loss
    net_out = self.phi(z_t, t, node_mask, edge_mask, context)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/equivariant_diffusion/en_diffusion.py", line 313, in phi
    net_out = self.dynamics._forward(t, x, node_mask, edge_mask, context)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/egnn/models.py", line 79, in _forward
    h_final, x_final = self.egnn(h, x, edges, node_mask=node_mask, edge_mask=edge_mask)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/egnn/egnn_new.py", line 191, in forward
    h, x = self._modules["e_block_%d" % i](h, x, edge_index, node_mask=node_mask, edge_mask=edge_mask, edge_attr=distances)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/egnn/egnn_new.py", line 141, in forward
    h, _ = self._modules["gcl_%d" % i](h, edge_index, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/afekaiki/EDM/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/egnn/egnn_new.py", line 61, in forward
    edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)
  File "/users/afekaiki/EDM/e3_diffusion_for_molecules/egnn/egnn_new.py", line 34, in edge_model
    out = torch.cat([source, target, edge_attr], dim=1)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.71 GiB. GPU 0 has a total capacity of 79.14 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 77.03 GiB memory in use. Of the allocated memory 71.11 GiB is allocated by PyTorch, and 5.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
